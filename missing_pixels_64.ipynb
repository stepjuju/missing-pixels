{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def pixelate_image(image, percent_pixels):\n",
    "    \"\"\"\n",
    "    :param image: numpy array of shape (H, W) or (1, H, W)\n",
    "    :param percent_pixels: from 0 to 1, percentage of removed pixels\n",
    "    :return: original image with some pixels removed, mask of removed pixels, and the correct pixels\n",
    "    \"\"\"\n",
    "    if image.ndim == 3 and image.shape[0] == 1:\n",
    "        image = image.squeeze(0)\n",
    "    elif image.ndim != 2:\n",
    "        raise ValueError(\"Image must be of shape (H, W) or (1, H, W)\")\n",
    "\n",
    "    mask = np.ones_like(image, dtype=np.uint8)\n",
    "    total_pixels = image.size\n",
    "    num_pixels_to_remove = int(total_pixels * percent_pixels)\n",
    "    indices_to_remove = np.random.choice(total_pixels, num_pixels_to_remove, replace=False)\n",
    "    indices_to_remove = np.unravel_index(indices_to_remove, image.shape)\n",
    "\n",
    "    correct_pixels = np.zeros_like(image)\n",
    "    correct_pixels[indices_to_remove] = image[indices_to_remove]\n",
    "    image[indices_to_remove] = 0\n",
    "    mask[indices_to_remove] = 0\n",
    "\n",
    "    return torch.from_numpy(image), torch.from_numpy(mask), torch.from_numpy(correct_pixels)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc = self.encoder(x)\n",
    "        middle = self.middle(enc)\n",
    "        dec = self.decoder(middle)\n",
    "        return dec\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "\n",
    "    def gaussian_window(self, size, sigma):\n",
    "        gauss = np.array([np.exp(-(x - size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(size)])\n",
    "        return torch.tensor(gauss / gauss.sum(), dtype=torch.float32)\n",
    "\n",
    "    def create_window(self, window_size, channel):\n",
    "        _1D_window = self.gaussian_window(window_size, 1.5).unsqueeze(1)\n",
    "        _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "        window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "        return window\n",
    "\n",
    "    def ssim(self, img1, img2, window_size=11, size_average=True):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "        window = self.create_window(window_size, channel)\n",
    "        window = window.to(img1.device)\n",
    "\n",
    "        mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
    "        mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
    "\n",
    "        mu1_sq = mu1.pow(2)\n",
    "        mu2_sq = mu2.pow(2)\n",
    "        mu1_mu2 = mu1 * mu2\n",
    "\n",
    "        sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
    "        sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
    "        sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
    "\n",
    "        C1 = 0.01 ** 2\n",
    "        C2 = 0.03 ** 2\n",
    "\n",
    "        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "        if size_average:\n",
    "            return ssim_map.mean()\n",
    "        else:\n",
    "            return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "    def forward(self, outputs, targets, mask):\n",
    "        mse = self.mse_loss(outputs * (1 - mask), targets * (1 - mask))\n",
    "        num_corrupted_pixels = torch.sum(1 - mask)\n",
    "        mse = mse.sum() / num_corrupted_pixels\n",
    "        ssim_value = self.ssim(outputs * (1 - mask), targets * (1 - mask))\n",
    "        return self.alpha * mse + (1 - self.alpha) * (1 - ssim_value)\n",
    "\n",
    "class GrayScaleImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None, subset_size=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(image_dir) for f in filenames if f.endswith('.png')]\n",
    "        if subset_size:\n",
    "            self.image_files = self.image_files[:subset_size]\n",
    "        self.transform = transform\n",
    "        self.masks = {}  # to store masks for each image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_files[index]\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        pixelated_img, mask, correct_pixels = pixelate_image(np.array(img), percent_pixels=0.2)\n",
    "        self.masks[index] = mask  # store the mask\n",
    "        return img, pixelated_img.float().unsqueeze(0), mask.float().unsqueeze(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "def evaluate_model(model, dataloader, device, num_samples=3):\n",
    "    model.eval()\n",
    "    sample_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, pixelated_imgs, masks in dataloader:\n",
    "            inputs = inputs.unsqueeze(1).to(device)\n",
    "            pixelated_imgs = pixelated_imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            outputs = model(pixelated_imgs)\n",
    "            outputs = outputs.squeeze(1)\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                if sample_count >= num_samples:\n",
    "                    break\n",
    "\n",
    "                original = inputs[i].cpu().squeeze().numpy()\n",
    "                corrupted = pixelated_imgs[i].cpu().squeeze().numpy()\n",
    "                reconstructed = outputs[i].cpu().numpy()\n",
    "                mask = masks[i].cpu().squeeze().numpy()\n",
    "\n",
    "                # apply the reconstructed pixels only where the mask is 0 (where pixels were removed)\n",
    "                filled_reconstructed = corrupted.copy()\n",
    "                filled_reconstructed[mask == 0] = reconstructed[mask == 0]\n",
    "\n",
    "                print(f'Sample {sample_count + 1}')\n",
    "                plt.figure(figsize=(15, 5))\n",
    "\n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.imshow(original, cmap='gray')\n",
    "                plt.title('Original Image')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.imshow(corrupted, cmap='gray')\n",
    "                plt.title('Pixelated Image')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.subplot(1, 3, 3)\n",
    "                plt.imshow(filled_reconstructed, cmap='gray')\n",
    "                plt.title('Filled Reconstructed Image')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                mse = np.mean((original - filled_reconstructed) ** 2)\n",
    "                psnr = 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "                ssim_value = ssim(original, filled_reconstructed, data_range=filled_reconstructed.max() - filled_reconstructed.min())\n",
    "\n",
    "                print(f'MSE: {mse:.4f}, PSNR: {psnr:.4f}, SSIM: {ssim_value:.4f}')\n",
    "\n",
    "                sample_count += 1\n",
    "\n",
    "            if sample_count >= num_samples:\n",
    "                break\n",
    "\n",
    "def train_model(learning_rate, optimizer, activation_function, batch_size, early_stopping_patience=3):\n",
    "    model = UNet().to(device)\n",
    "    criterion = CombinedLoss(alpha=0.5)\n",
    "    optimizer = optimizer(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    num_epochs = 10\n",
    "    model.train()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_hyperparams = None\n",
    "    best_model = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch')\n",
    "        for inputs, pixelated_imgs, masks in progress_bar:\n",
    "            inputs = inputs.to(device)\n",
    "            pixelated_imgs = pixelated_imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(pixelated_imgs)\n",
    "\n",
    "            # loss only for masked pixels\n",
    "            loss = criterion(outputs, inputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=running_loss / len(train_loader))\n",
    "\n",
    "            # update progress bar every 100 (adjust to make it less frequently)\n",
    "            if progress_bar.n % 100 == 0:\n",
    "                progress_bar.set_postfix(loss=running_loss / (progress_bar.n + 1))\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_pixelated_imgs, val_masks in val_loader:\n",
    "                val_inputs = val_inputs.to(device)\n",
    "                val_pixelated_imgs = val_pixelated_imgs.to(device)\n",
    "                val_masks = val_masks.to(device)\n",
    "                val_outputs = model(val_pixelated_imgs)\n",
    "                val_loss += criterion(val_outputs, val_inputs, val_masks).item()\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            best_hyperparams = (learning_rate, optimizer, activation_function, batch_size)\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve == early_stopping_patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    return best_val_loss, best_model, best_hyperparams\n",
    "\n",
    "transform_list = [transforms.ToTensor()]\n",
    "transform = transforms.Compose(transform_list)\n",
    "\n",
    "image_dir = 'data/training_preprocessed'\n",
    "val_dir = 'data/val_data'\n",
    "\n",
    "train_dataset = GrayScaleImageDataset(image_dir=image_dir, transform=transform)\n",
    "val_dataset = GrayScaleImageDataset(image_dir=val_dir, transform=transform)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "hyperparams = {\n",
    "    'learning_rate': [0.001, 0.01],\n",
    "    'optimizer': [optim.Adam],\n",
    "    'activation_function': [F.relu],\n",
    "    'batch_size': [8, 16]\n",
    "}\n",
    "\n",
    "hyperparam_combinations = list(itertools.product(*hyperparams.values()))\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_hyperparams = None\n",
    "best_model = None\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "for idx, combination in enumerate(hyperparam_combinations):\n",
    "    lr, opt, act_func, batch_size = combination\n",
    "    model_name = f\"models/model_v_20{idx + 1}.pth\"\n",
    "    plot_name = f\"plots/results_v_20{idx + 1}.png\"\n",
    "    print(f'Training with learning_rate={lr}, optimizer={opt.__name__}, activation_function={act_func.__name__}, batch_size={batch_size}')\n",
    "\n",
    "    val_loss, model_state, best_hyperparams = train_model(lr, opt, act_func, batch_size, early_stopping_patience=10)\n",
    "\n",
    "    torch.save(model_state, model_name)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_hyperparams = combination\n",
    "        best_model = model_state\n",
    "\n",
    "    model = UNet().to(device)\n",
    "    model.load_state_dict(model_state)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    evaluate_model(model, val_loader, device, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_hyperparams:\n",
    "    print(f'Best Hyperparameters: learning_rate={best_hyperparams[0]}, optimizer={best_hyperparams[1].__class__.__name__}, activation_function={best_hyperparams[2].__name__}, batch_size={best_hyperparams[3]}')\n",
    "    print(f'Best Validation Loss: {best_loss:.4f}')\n",
    "\n",
    "    torch.save(best_model, \"models/model_64.pth\")\n",
    "\n",
    "    model = UNet().to(device)\n",
    "    model.load_state_dict(best_model)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=best_hyperparams[3], shuffle=False)\n",
    "    evaluate_model(model, val_loader, device, num_samples=3)\n",
    "else:\n",
    "    print(\"No valid hyperparameter combination found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
